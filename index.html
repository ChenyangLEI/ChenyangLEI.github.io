<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <!-- Hi, Jon Here. Please DELETE the two <script> tags below if you use this HTML, otherwise my analytics will track your page -->
  <!-- Global site tag (gtag.js) - Google Analytics -->
<!--   <script async src="https://www.googletagmanager.com/gtag/js?id=UA-7580334-2"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-7580334-2');
  </script>
 -->
  <title>Chenyang Lei (雷晨阳)</title>
  
  <meta name="author" content="Jon Barron">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <!-- <link rel="icon" type="image/png" href="images/seal_icon.png"> -->
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Chenyang Lei (雷晨阳)</name>
              </p>
              <p>Chenyang Lei received his Ph.D. in computer science from the Hong Kong University of Science and Technology (HKUST), supervised by <a href="https://cqf.io">Qifeng Chen</a>. He obtained his Bachelor's degree at Zhejiang University in 2018.  
              </p>



              


              <p style="text-align:center">
                <a href="mailto:leichenyang7@gmail.com">Email</a> &nbsp/&nbsp
                <a href="images/Chenyang_Lei__CV.pdf">CV</a> &nbsp/&nbsp 
                <a href="https://github.com/ChenyangLEI">Github</a> &nbsp/&nbsp 
                <!-- <a href="data/JonBarron-CV.pdf">CV</a> &nbsp/&nbsp -->
                <!-- <a href="data/JonBarron-bio.txt">Biography</a> &nbsp/&nbsp -->
                <a href="https://scholar.google.com/citations?user=CuGF_pEAAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
                <a href="https://www.linkedin.com/in/%E6%99%A8%E9%98%B3-%E9%9B%B7-73565b149/">Linked In</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/chenyanglei.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/chenyanglei_Circle.png" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
                <tbody>
                  <tr>
                    <td>
                      <!-- <heading> -->
                        <!-- <font color="black">News</font> -->
                      <!-- </heading> -->
                      <p>
                      <ul>
                        <li>News (Aug 2022): I passed my Ph.D. defense!</li>
                        <li>News (Apr 2021): I started an internship at Nvidia, supervised by Orazio Gallo, Abhishek Badki and Hang Su. </li>
                        <li>News (Mar 2022): One paper is accepted to CVPR 2022.</li>
                        <li>News (Dec 2021): One paper is accepted to TPAMI 2021.</li>
                        <li>News (Apr 2021): I started an internship at MSRA, supervised by Steve Lin, Zhirong Wu and Xiao Sun. </li>
                        <li>News (Mar 2021): Two papers are accepted to CVPR 2021.</li>
                      </ul>
                      </p>
                    </td>
                  </tr>
                </tbody>


            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research</heading>
              <p>
                I'm interested in Computational photography, Video temporal consistency, Polarization in vision and 3D vision.
              </p>
            </td>
          </tr>
        </tbody></table>


        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

          <tr onmouseout="sfp_stop()" onmouseover="sfp_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='sfp_image'>
                  <img src='images/sfp_after.png' width="160"></div>
                <img src='images/sfp_before.png' width="160">
              </div>
              <script type="text/javascript">
                function sfp_start() {
                  document.getElementById('sfp_image').style.opacity = "1";
                }

                function sfp_stop() {
                  document.getElementById('sfp_image').style.opacity = "0";
                }
                videodepth_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle>Shape from Polarization for Complex Scenes in the Wild</papertitle>
              </a>
              <br>
              <strong>Chenyang Lei*</strong>,
              Chenyang Qi*,
              Jiaxin Xie*,
              Na Fan, 
              <a href="http://vladlen.info/">Vladlen Koltun </a>, 
              <a href="http://cqf.io">Qifeng Chen</a>
              <br>
              <em>CVPR</em>, 2022  
              <br>
              <a href="https://arxiv.org/pdf/2112.11377.pdf">arxiv</a> / 
              <a href="https://github.com/ChenyangLEI/sfp-wild">code</a>  

              <p></p>
              <p>We present a new data-driven approach with physics-based priors to scene-level normal estimation from a single polarization image. </p>
            </td>

          </tr>  


          <tr onmouseout="imagination_stop()" onmouseover="imagination_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='imagination_image'>
                  <img src='images/imagination_after.png' width="160"></div>
                <img src='images/imagination_before.png' width="160">
              </div>
              <script type="text/javascript">
                function imagination_start() {
                  document.getElementById('imagination_image').style.opacity = "1";
                }

                function imagination_stop() {
                  document.getElementById('imagination_image').style.opacity = "0";
                }
                videodepth_stop()
              </script>
            </td>

            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle>Towards Photorealistic Colorization by Imagination</papertitle>
              </a>
              <br>
              <strong>Chenyang Lei*</strong>,
              Yue Wu*,
              <a href="http://cqf.io">Qifeng Chen</a>
              <br>
              <em>In Submission </em>, 2022  
              <br>
              <!-- <a href=""></a>  -->
              <p></p>
              <p>We present a novel approach to automatic image colorization by imitating the imagination process of human experts. </p>
            </td>
 
          <tr onmouseout="DVPvp_stop()" onmouseover="DVPvp_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='DVPvp_image'>
                  <img src='images/dvpvp_after.png' width="160"></div>
                <img src='images/dvpvp_before.png' width="160">
              </div>
              <script type="text/javascript">
                function DVPvp_start() {
                  document.getElementById('DVPvp_image').style.opacity = "1";
                }

                function DVPvp_stop() {
                  document.getElementById('DVPvp_image').style.opacity = "0";
                }
                videodepth_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle>Deep Video Prior for Video Consistency and Propagation</papertitle>
              </a>
              <br>
              <strong>Chenyang Lei</strong>,
              Yazhou Xing,
              Hao Ouyang, 
              <a href="http://cqf.io">Qifeng Chen</a>
              <br>
              <em>TPAMI </em>, 2021  
              <br>
              <a href="https://github.com/ChenyangLEI/deep-video-prior">code</a> 
              <p></p>
              <p>We extend the deep video prior (NeurIPS 2020) to video propagation. We also improve the training efficiency for deep video prior. </p>
            </td>
          </tr>  

          <tr onmouseout="flash_stop()" onmouseover="flash_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='flash_image'>
                  <img src='images/flash_after.jpg' width="160"></div>
                <img src='images/flash_before.jpg' width="160">
              </div>
              <script type="text/javascript">
                function flash_start() {
                  document.getElementById('flash_image').style.opacity = "1";
                }

                function flash_stop() {
                  document.getElementById('flash_image').style.opacity = "0";
                }
                videodepth_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <!-- <a href="https://arxiv.org/abs/2010.11838"> -->
                <papertitle>Robust Reflection Removal with Reflection-free Flash-only Cues                </papertitle>
              </a>
              <br>
              <strong>Chenyang Lei</strong>,
              <a href="http://cqf.io">Qifeng Chen</a>
              <br>
              <em>CVPR </em>, 2021  
              <br>
              <a href="https://arxiv.org/pdf/2103.04273.pdf">arxiv</a> / 
              <a href="https://github.com/ChenyangLEI/flash-reflection-removal">code</a> / 
              <a href="flashrr_rfc/index.html">project website</a> 
              <p></p>
              <p>We propose a simple yet effective reflection-free cue for robust reflection removal from a pair of flash and ambient (no-flash) images. 
                The reflection-free cue exploits a flash-only image obtained by subtracting the ambient image from the corresponding flash image in raw data space. 
                The flash-only image is equivalent to an image taken in a dark environment with only a flash on.  </p>
            </td>
          </tr>  
          <tr onmouseout="sim_stop()" onmouseover="sim_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='sim_image'>
                  <img src='images/simulator_after.PNG' width="160"></div>
                <img src='images/simulator_before.PNG' width="160">
              </div>
              <script type="text/javascript">
                function sim_start() {
                  document.getElementById('sim_image').style.opacity = "1";
                }

                function sim_stop() {
                  document.getElementById('sim_image').style.opacity = "0";
                }
                videodepth_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <!-- <a href="https://arxiv.org/abs/2010.11838"> -->
                <papertitle>Neural Camera Simulators</papertitle>
              </a>
              <br>
              <a>Hao Ouyang*</a>,
              <a>Zifan Shi*</a>,
              <strong>Chenyang Lei</strong>,
              <a>Ka Lung Law</a>,
              <a href="http://cqf.io">Qifeng Chen</a>
              <br>
              <em>CVPR </em>, 2021  

              <br>
              <a href="https://cqf.io/papers/Neural_Camera_Simulators_CVPR2021.pdf">paper</a>  /
              <a href="https://github.com/ken-ouyang/neural_image_simulator">code</a>  
              <!-- <a href="DVP/index.html">project website</a> -->
              <p></p>
              <p>We present a controllable camera simulator based on deep neural networks to synthesize raw image data under different camera settings, including exposure time, ISO, and aperture. </p>
            </td>
          </tr>  

          <tr onmouseout="DVP_stop()" onmouseover="DVP_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='DVP_image'>
                  <img src='images/DVP_after.JPG' width="160"></div>
                <img src='images/DVP_before.JPG' width="160">
              </div>
              <script type="text/javascript">
                function DVP_start() {
                  document.getElementById('DVP_image').style.opacity = "1";
                }

                function DVP_stop() {
                  document.getElementById('DVP_image').style.opacity = "0";
                }
                videodepth_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2010.11838">
                <papertitle>Blind Video Temporal Consistency via Deep Video Prior</papertitle>
              </a>
              <br>
              <strong>Chenyang Lei*</strong>,
              Yazhou Xing*,
              <a href="http://cqf.io">Qifeng Chen</a>
              <br>
              <em>NeurIPS </em>, 2020  
              <br>
              <a href="https://arxiv.org/abs/2010.11838">arxiv</a> / 
              <a href="https://github.com/ChenyangLEI/deep-video-prior">code</a> / 
              <a href="DVP/index.html">project website</a>
              <p></p>
              <p>Applying image processing algorithms independently to each video frame often leads to temporal inconsistency in the resulted video. To address this issue,
                we present a novel and general approach for blind temporal video consistency. </p>
            </td>
          </tr>  

          <tr onmouseout="videodepth_stop()" onmouseover="videodepth_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='videodepth_image'>
                  <img src='images/depth_after.JPG' width="160"></div>
                <img src='images/depth_before.JPG' width="160">
              </div>
              <script type="text/javascript">
                function videodepth_start() {
                  document.getElementById('videodepth_image').style.opacity = "1";
                }

                function videodepth_stop() {
                  document.getElementById('videodepth_image').style.opacity = "0";
                }
                videodepth_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/pdf/1912.12874.pdf">
                <papertitle>Video Depth Estimation by Fusing Flow-to-Depth Proposals</papertitle>
              </a>
              <br>
              <a href="https://jiaxinxie97.github.io/">Jiaxin Xie</a>,
              <strong>Chenyang Lei</strong>,
              <a href="https://scholar.google.com/citations?user=gIBLutQAAAAJ&hl=en">Zhuwen Li</a>,
              <a href="http://www.cs.columbia.edu/~lierranli/">Li Erran Li</a>,
              <a href="http://cqf.io">Qifeng Chen</a>
              <br>
              <em>IROS </em>, 2020  
              <br>
              <a href="https://arxiv.org/pdf/1912.12874.pdf">arXiv</a> / 
              <a href="https://github.com/jiaxinxie97/Video-depth-estimation">code</a> / 
              <a href="https://jiaxinxie97.github.io/Jiaxin-Xie/FDNet/FDNet">project website</a>
              <p></p>
              <p>We present an approach with a differentiable flowto-depth layer for video depth estimation.</p>
            </td>
          </tr>  

          <tr onmouseout="polar_rr_stop()" onmouseover="polar_rr_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='polar_rr_image'>
                  <img src='images/polarRR_after.jpg' width="160"></div>
                <img src='images/PolarRR_before.jpg' width="160">
              </div>
              <script type="text/javascript">
                function polar_rr_start() {
                  document.getElementById('polar_rr_image').style.opacity = "1";
                }

                function polar_rr_stop() {
                  document.getElementById('polar_rr_image').style.opacity = "0";
                }
                polar_rr_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://cqf.io/papers/Polarized_Reflection_Removal_CVPR2020.pdf">
                <papertitle>Polarized Reflection Removal with Perfect Alignment in the Wild</papertitle>
              </a>
              <br>
              <strong>Chenyang Lei</strong>,
              Xuhua Huang,
              Mengdi Zhang,
              Qiong Yan,
              Wenxiu Sun,
              <a href="http://cqf.io">Qifeng Chen</a>
              <br>
              <em>CVPR</em>, 2020  
              <br>
              <a href="https://cqf.io/papers/Polarized_Reflection_Removal_CVPR2020.pdf">arXiv</a> / 
              <a href="https://github.com/ChenyangLEI/CVPR2020-Polarized-Reflection-Removal-with-Perfect-Alignment">code</a> / 
              <a href="polar_rr/index.html">project website</a>

              <p></p>
              <p>Polarization information and perfect alignment are utilized to remove reflection accurately.</p>
            </td>
          </tr>  







          <tr onmouseout="porshadmanip_stop()" onmouseover="porshadmanip_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='porshadmanip_image'>
                  <img src='images/Color_before.jpg' width="160"></div>
                <img src='images/Color_after.jpg' width="160">
              </div>
              <script type="text/javascript">
                function porshadmanip_start() {
                  document.getElementById('porshadmanip_image').style.opacity = "1";
                }

                function porshadmanip_stop() {
                  document.getElementById('porshadmanip_image').style.opacity = "0";
                }
                porshadmanip_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://cqf.io/papers/Fully_Automatic_Video_Colorization_CVPR2019.pdf">
                <papertitle>Fully Automatic Video Colorization with Self Regularization and Diversity</papertitle>
              </a>
              <br>
              <strong>Chenyang Lei</strong>,
              <a href="http://cqf.io">Qifeng Chen</a>
              <br>
              <em>CVPR</em>, 2019  
              <br>
              <a href="https://leichenyang.weebly.com/project-color.html">project page</a> / 
              <a href="https://www.youtube.com/watch?v=Y15uv2jnK-4&feature=youtu.be">video</a> /
              <a href="https://github.com/ChenyangLEI/Fully-Automatic-Video-Colorization-with-Self-Regularization-and-Diversity">code</a>
              <p></p>
              <p>The first dedicated video colorization method without any user input.</p>
            </td>
          </tr>  


        </tbody></table>



         <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>Services</heading>
                <ul>
                  <li>Program Committee/Reviewers: CVPR, ICCV, TPAMI, IJCV, AAAI, TIP, IJCAI, IROS, TVCG
                </ul>
            </td>
          </tr>
        </tbody></table>
        
         <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>Honors and Awards</heading>
                <ul>
                  <li>RedBird PhD Scholarship, HKUST, 2021</li>
                  <li>SENG Academic Award for Continuing PhD students, HKUST, 2020</li>
                  <li>National Scholarship, 2017</li>
                  <li>Outstanding Graduate (Zhejiang University), 2018</li>            
                  <li>Texas Instruments Scholarship, 2017</li>            
                  <li>First-Class Scholarship for Outstanding Merits, 2017</li>            
                  <li>Excellent Student Award, 2016, 2017</li>              
                </ul>              
            </td>
          </tr>
        </tbody></table>

         <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>Teaching Assistant</heading>
                <ul>
                  <li>COMP 4901J: Deep Learning in Computer Vision (Spring 2019)</li>
                  <li>COMP 3031: Principle of Programming Languages (Fall 2019)</li>          
                  <li>COMP2011: Programming with C++ (Spring 2021)</li>          
                  
                </ul>
           </td>
          </tr>
        </tbody></table>


        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:center;font-size:small;">Thank <a href="https://jonbarron.info/">Dr. Jon Barron</a> for sharing the source code of his personal page.</p>
                <!-- <br> -->
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

<a href="https://www.easycounter.com/">
<img src="https://www.easycounter.com/counter.php?chenyang"
border="0" alt="Web Counters"></a>
<br><a href="https://www.easycounter.com/">Web Counters</a>

</html>
