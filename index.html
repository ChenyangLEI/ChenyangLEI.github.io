<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <!-- Hi, Jon Here. Please DELETE the two <script> tags below if you use this HTML, otherwise my analytics will track your page -->
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-7580334-2"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-7580334-2');
  </script>

  <title>Chenyang Lei (雷晨阳)</title>
  
  <meta name="author" content="Jon Barron">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <!-- <link rel="icon" type="image/png" href="images/seal_icon.png"> -->
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Chenyang Lei (雷晨阳)</name>
              </p>
              <p>Chenyang Lei is a second year Ph.D. student at the Hong Kong University of Science and Technology (HKUST), supervised by <a href="https://cqf.io">Qifeng Chen</a>. He obtained his Bachelor's degree at Zhejiang University in 2018.  
              </p>
<!--               <p>
                At Google I've worked on <a href="https://ai.googleblog.com/2014/04/lens-blur-in-new-google-camera-app.html">Lens Blur</a>, <a href="https://ai.googleblog.com/2014/10/hdr-low-light-and-high-dynamic-range.html">HDR+</a>, <a href="https://www.google.com/get/cardboard/jump/">Jump</a>, <a href="https://ai.googleblog.com/2017/10/portrait-mode-on-pixel-2-and-pixel-2-xl.html">Portrait Mode</a>, and <a href="https://www.youtube.com/watch?v=JSnB06um5r4">Glass</a>. I did my PhD at <a href="http://www.eecs.berkeley.edu/">UC Berkeley</a>, where I was advised by <a href="http://www.cs.berkeley.edu/~malik/">Jitendra Malik</a> and funded by the <a href="http://www.nsfgrfp.org/">NSF GRFP</a>. I did my bachelors at the <a href="http://cs.toronto.edu">University of Toronto</a>.
              </p> -->
              <p style="text-align:center">
                <a href="mailto:leichenyang7@gmail.com">Email</a> &nbsp/&nbsp
                <a href="images/Chenyang_Lei__CV.pdf">CV</a> &nbsp/&nbsp 
                <!-- <a href="data/JonBarron-CV.pdf">CV</a> &nbsp/&nbsp -->
                <!-- <a href="data/JonBarron-bio.txt">Biography</a> &nbsp/&nbsp -->
                <!-- <a href="https://scholar.google.com/citations?hl=en&user=jktWnL8AAAAJ">Google Scholar</a> &nbsp/&nbsp -->
                <a href="https://www.linkedin.com/in/%E6%99%A8%E9%98%B3-%E9%9B%B7-73565b149/">Linked In</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/chenyanglei.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/chenyanglei_Circle.png" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research</heading>
              <p>
                I'm interested in Low-level vision, Computational photography, Image and video synthesis, Image and video processing, and 3D vision.
              </p>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

    
<!--           <tr onmouseout="nerf_stop()" onmouseover="nerf_start()"  bgcolor="#ffffd0">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='nerf_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/vase_small.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='images/vase_still.png' width="160">
              </div>
              <script type="text/javascript">
                function nerf_start() {
                  document.getElementById('nerf_image').style.opacity = "1";
                }

                function nerf_stop() {
                  document.getElementById('nerf_image').style.opacity = "0";
                }
                nerf_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="http://www.matthewtancik.com/nerf">
                <papertitle>NeRF: Representing Scenes as Neural Radiance Fields for View Synthesis
</papertitle>
              </a>
              <br>
              <a href="https://people.eecs.berkeley.edu/~bmild/">Ben Mildenhall*</a>,
              <a href="https://people.eecs.berkeley.edu/~pratul/">Pratul Srinivasan*</a>,
              <a href="http://matthewtancik.com/">Matthew Tancik*</a>,
              <strong>Jonathan T. Barron</strong>,
              <a href="http://cseweb.ucsd.edu/~ravir/">Ravi Ramamoorthi</a>,
              <a href="https://www2.eecs.berkeley.edu/Faculty/Homepages/yirenng.html">Ren Ng</a>
              <br>
        <em>arXiv</em>, 2020  
              <br>
              <a href="http://www.matthewtancik.com/nerf">project page</a>
        /
              <a href="https://arxiv.org/abs/2003.08934">arXiv</a>
        /
              <a href="https://www.youtube.com/watch?v=JuH79E8rdKc">video</a>
        /
              <a href="https://github.com/bmild/nerf">code</a>
              <p></p>
              <p>
              Training a tiny non-convolutional neural network to reproduce a scene using volume rendering achieves photorealistic view synthesis.</p>
            </td>
          </tr>  -->
          
          <tr onmouseout="DVP_stop()" onmouseover="DVP_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='DVP_image'>
                  <img src='images/DVP_after.JPG' width="160"></div>
                <img src='images/DVP_before.JPG' width="160">
              </div>
              <script type="text/javascript">
                function DVP_start() {
                  document.getElementById('DVP_image').style.opacity = "1";
                }

                function DVP_stop() {
                  document.getElementById('DVP_image').style.opacity = "0";
                }
                videodepth_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
<!--               <a href="https://arxiv.org/pdf/1912.12874.pdf"> -->
                <papertitle>Blind Temporal Video Consistency via Deep Video Prior</papertitle>
              </a>
              <br>
              <strong>Chenyang Lei*</strong>,
              Yazhou Xing*,
              <a href="http://cqf.io">Qifeng Chen</a>
              <br>
              <em>NeurIPS </em>, 2020  
              <br>
<!--               <a href="https://arxiv.org/pdf/1912.12874.pdf">arXiv</a> -->
              <p></p>
              <p>Applying image processing algorithms independently to each video frame often leads to temporal inconsistency in the resulted video. To address this issue,
                we present a novel and general approach for blind temporal video consistency. </p>
            </td>
          </tr>  

          <tr onmouseout="videodepth_stop()" onmouseover="videodepth_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='videodepth_image'>
                  <img src='images/depth_after.JPG' width="160"></div>
                <img src='images/depth_before.JPG' width="160">
              </div>
              <script type="text/javascript">
                function videodepth_start() {
                  document.getElementById('videodepth_image').style.opacity = "1";
                }

                function videodepth_stop() {
                  document.getElementById('videodepth_image').style.opacity = "0";
                }
                videodepth_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/pdf/1912.12874.pdf">
                <papertitle>Video Depth Estimation by Fusing Flow-to-Depth Proposals</papertitle>
              </a>
              <br>
              Jiaxin Xie,
              <strong>Chenyang Lei</strong>,
              <a href="https://scholar.google.com/citations?user=gIBLutQAAAAJ&hl=en">Zhuwen Li</a>,
              <a href="http://www.cs.columbia.edu/~lierranli/">Li Erran Li</a>,
              <a href="http://cqf.io">Qifeng Chen</a>
              <br>
              <em>IROS </em>, 2020  
              <br>
              <a href="https://arxiv.org/pdf/1912.12874.pdf">arXiv</a>
              <p></p>
              <p>We present an approach with a differentiable flowto-depth layer for video depth estimation.</p>
            </td>
          </tr>  

          <tr onmouseout="polar_rr_stop()" onmouseover="polar_rr_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='polar_rr_image'>
                  <img src='images/polarRR_after.jpg' width="160"></div>
                <img src='images/PolarRR_before.jpg' width="160">
              </div>
              <script type="text/javascript">
                function polar_rr_start() {
                  document.getElementById('polar_rr_image').style.opacity = "1";
                }

                function polar_rr_stop() {
                  document.getElementById('polar_rr_image').style.opacity = "0";
                }
                polar_rr_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://cqf.io/papers/Polarized_Reflection_Removal_CVPR2020.pdf">
                <papertitle>Polarized Reflection Removal with Perfect Alignment in the Wild</papertitle>
              </a>
              <br>
              <strong>Chenyang Lei</strong>,
              Xuhua Huang,
              Mengdi Zhang,
              Qiong Yan,
              Wenxiu Sun,
              <a href="http://cqf.io">Qifeng Chen</a>
              <br>
              <em>CVPR</em>, 2020  
              <br>
              <a href="https://cqf.io/papers/Polarized_Reflection_Removal_CVPR2020.pdf">arXiv</a> / 
              <a href="https://github.com/ChenyangLEI/CVPR2020-Polarized-Reflection-Removal-with-Perfect-Alignment">code</a>
              <p></p>
              <p>Polarization information and perfect alignment are utilized to remove reflection accurately.</p>
            </td>
          </tr>  







          <tr onmouseout="porshadmanip_stop()" onmouseover="porshadmanip_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='porshadmanip_image'>
                  <img src='images/Color_before.jpg' width="160"></div>
                <img src='images/Color_after.jpg' width="160">
              </div>
              <script type="text/javascript">
                function porshadmanip_start() {
                  document.getElementById('porshadmanip_image').style.opacity = "1";
                }

                function porshadmanip_stop() {
                  document.getElementById('porshadmanip_image').style.opacity = "0";
                }
                porshadmanip_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://cqf.io/papers/Fully_Automatic_Video_Colorization_CVPR2019.pdf">
                <papertitle>Fully Automatic Video Colorization with Self Regularization and Diversity</papertitle>
              </a>
              <br>
              <strong>Chenyang Lei</strong>,
              <a href="http://cqf.io">Qifeng Chen</a>
              <br>
              <em>CVPR</em>, 2019  
              <br>
              <a href="https://leichenyang.weebly.com/project-color.html">project page</a> / 
              <a href="https://www.youtube.com/watch?v=Y15uv2jnK-4&feature=youtu.be">video</a> /
              <a href="https://github.com/ChenyangLEI/Fully-Automatic-Video-Colorization-with-Self-Regularization-and-Diversity">code</a>
              <p></p>
              <p>The first dedicated video colorization method without any user input.</p>
            </td>
          </tr>  
    <!-- 
          <tr onmouseout="lighthouse_stop()" onmouseover="lighthouse_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='lh_image'><video width=100% height=100% muted autoplay loop>
                <source src="images/rings_crop.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='images/rings.png' width="160">
              </div>
              <script type="text/javascript">
                function lighthouse_start() {
                  document.getElementById('lh_image').style.opacity = "1";
                }

                function lighthouse_stop() {
                  document.getElementById('lh_image').style.opacity = "0";
                }
                lighthouse_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://people.eecs.berkeley.edu/~pratul/lighthouse/">
                <papertitle>Lighthouse: Predicting Lighting Volumes for Spatially-Coherent Illumination</papertitle>
              </a>
              <br>
              <a href="https://people.eecs.berkeley.edu/~pratul/">Pratul Srinivasan*</a>,
              <a href="https://people.eecs.berkeley.edu/~bmild/">Ben Mildenhall*</a>,
              <a href="http://matthewtancik.com/">Matthew Tancik</a>,
              <strong>Jonathan T. Barron</strong>,
              <a href="https://research.google/people/RichardTucker/">Richard Tucker</a>,
              <a href="https://www.cs.cornell.edu/~snavely/">Noah Snavely</a>
              <br>
        <em>CVPR</em>, 2020  
              <br>
              <a href="https://people.eecs.berkeley.edu/~pratul/lighthouse/">project page</a>
        /
              <a href="https://arxiv.org/abs/2003.08367">arXiv</a>
        /
              <a href="https://www.youtube.com/watch?v=KsiZpUFPqIU">video</a>
              <p></p>
              <p>We predict a volume from an input stereo pair that can be used to calculate incident lighting at any 3D point within a scene.</p>
            </td>
          </tr>  




          <tr onmouseout="friendly_stop()" onmouseover="friendly_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='friendly_image'><img src='images/friendly_after.png'></div>
                <img src='images/friendly_before.png'>
              </div>
              <script type="text/javascript">
                function friendly_start() {
                  document.getElementById('friendly_image').style.opacity = "1";
                }

                function friendly_stop() {
                  document.getElementById('friendly_image').style.opacity = "0";
                }
                friendly_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://drive.google.com/file/d/1w_0djhL0QgC_fbehnJ0c-J23_kW_420p/view?usp=sharing">
                <papertitle>A Hardware-Friendly Bilateral Solver for Real-Time Virtual Reality Video</papertitle>
              </a>
              <br>
              <a href="https://homes.cs.washington.edu/~amrita/">Amrita Mazumdar</a>, <a href="http://homes.cs.washington.edu/~armin/">Armin Alaghi</a>, <strong>Jonathan T. Barron</strong>, <a href="https://www.cs.unc.edu/~gallup/">David Gallup</a>, <a href="https://homes.cs.washington.edu/~luisceze/">Luis Ceze</a>, <a href="https://homes.cs.washington.edu/~oskin/">Mark Oskin</a>, <a href="http://homes.cs.washington.edu/~seitz/">Steven M. Seitz</a>
              <br>
              <em>High-Performance Graphics (HPG)</em>, 2017
              <br>
              <a href="https://sampa.cs.washington.edu/projects/vr-hw.html">project page</a>
              <p></p>
              <p>A reformulation of the bilateral solver can be implemented efficiently on GPUs and FPGAs.</p>
            </td>
          </tr> -->

        </tbody></table>

        
         <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>Teaching Assistant</heading>
                <ul>
                  <li>COMP 4901J: Deep Learning in Computer Vision (Spring 2019)</li>
                  <li>COMP 3031: Principle of Programming Languages (Fall 2019)</li>              
                </ul>

<!--               <p>
              COMP 4901J: Deep Learning in Computer Vision (Spring 2019)
              </p>
              <p>
               COMP 3031: Principle of Programming Languages (Fall 2019)
              </p>
 -->            </td>
          </tr>
        </tbody></table>

         <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>Honors and Awards</heading>
                <ul>
                  <li>SENG Academic Award for Continuing PhD students, HKUST, 2020</li>
                  <li>National Scholarship, 2017</li>
                  <li>Outstanding Graduate (Zhejiang University), 2018</li>            
                  <li>Texas Instruments Scholarship, 2017</li>            
                  <li>First-Class Scholarship for Outstanding Merits, 2017</li>            
                  <li>Excellent Student Award, 2016, 2017</li>              
                </ul>

<!--               <p>
              National Scholarship, 2017
              </p>
              <p>
              Outstanding Graduate (Zhejiang University), 2018
              </p>
              <p>
              Texas Instruments Scholarship, 2017
              </p>
              <p>
              First-Class Scholarship for Outstanding Merits, 2017
              </p>
              <p>
              Excellent Student Award, 2016, 2017
              </p> -->
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:center;font-size:small;">Thank <a href="https://jonbarron.info/">Dr. Jon Barron</a> for sharing the source code of his personal page.</p>
                <!-- <br> -->
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>
